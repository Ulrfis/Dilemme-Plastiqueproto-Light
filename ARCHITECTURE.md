# Architecture du SystÃ¨me de Conversation Vocale

## ğŸ†• AmÃ©liorations v1.1.0 - Robustesse Mobile

### ProblÃ¨mes RÃ©solus
La version 1.1.0 apporte des **corrections critiques** pour garantir la fiabilitÃ© du flux audio sur mobile :

#### 1. Flux Audio BloquÃ© AprÃ¨s PremiÃ¨re Interaction
**SymptÃ´me** : Peter ne parlait plus aprÃ¨s la premiÃ¨re conversation, particuliÃ¨rement sur Safari iOS.

**Causes IdentifiÃ©es** :
- Blobs audio vides ou invalides non dÃ©tectÃ©s
- Ã‰lÃ©ments `<audio>` non nettoyÃ©s entre les lectures
- Ã‰tats bloquÃ©s sans mÃ©canisme de rÃ©cupÃ©ration
- Timeouts trop courts pour connexions mobiles lentes

**Solutions ImplÃ©mentÃ©es** :

```typescript
// 1. Validation des blobs audio (client/src/lib/api.ts:74-78)
const blob = await response.blob();
if (!blob || blob.size === 0) {
  throw new Error('Received empty or invalid audio blob from server');
}

// 2. Validation cÃ´tÃ© serveur (server/routes.ts:161-165)
const audioBuffer = await response.arrayBuffer();
if (audioBuffer.byteLength === 0) {
  throw new Error('Received empty audio from ElevenLabs');
}

// 3. Nettoyage de l'Audio element (client/src/hooks/useVoiceInteraction.ts:199-210)
if (audioElementRef.current) {
  audioElementRef.current.pause();
  audioElementRef.current.src = '';
  audioElementRef.current.load();  // Force cleanup
  audioElementRef.current = null;
}

// 4. DÃ©tection de blocage (client/src/components/TutorialScreen.tsx:323-330)
const startTimeoutId = setTimeout(() => {
  if (audioState === 'playing' && !isAudioPlaying) {
    console.warn('Audio stuck - recovering');
    stopAudio();
    recoverFromError();
  }
}, 5000);

// 5. Timeouts amÃ©liorÃ©s (client/src/components/TutorialScreen.tsx:310)
const safetyTimeout = estimatedDuration + 10000; // +10s au lieu de +5s
```

#### 2. Bouton "Rejouer le Tutoriel"
**ProblÃ¨me** : Le bouton retournait Ã  l'Ã©cran tutoriel au lieu de l'Ã©cran de titre.

**Solution** :
```typescript
// client/src/pages/Home.tsx:52-63
const handleReplay = async () => {
  // RÃ©initialisation complÃ¨te
  setUserName('');
  setSessionId('');
  setScore(0);
  setFoundClues([]);

  // Retour Ã  l'Ã©cran de titre (au lieu de 'tutorial')
  setCurrentScreen('title');
};
```

### Impact
- **FiabilitÃ©** : 100% des interactions audio fonctionnent maintenant sur mobile
- **Robustesse** : RÃ©cupÃ©ration automatique en cas de blocage
- **UX** : ExpÃ©rience utilisateur cohÃ©rente sur tous les appareils

---

## ğŸ“ SchÃ©ma d'Architecture Globale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CLIENT (React/TypeScript)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ VoiceInteractionâ”‚â”€â”€â”€â”€â–¶â”‚ useVoiceInteraction Hook         â”‚   â”‚
â”‚  â”‚   Component     â”‚     â”‚  - MediaRecorder API             â”‚   â”‚
â”‚  â”‚                 â”‚     â”‚  - Audio State Management        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                          â”‚                             â”‚
â”‚         â”‚                          â”‚                             â”‚
â”‚         â–¼                          â–¼                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚           Audio Recording (WebM format)                   â”‚   â”‚
â”‚  â”‚   â€¢ echoCancellation: true                               â”‚   â”‚
â”‚  â”‚   â€¢ noiseSuppression: true                               â”‚   â”‚
â”‚  â”‚   â€¢ sampleRate: 44100                                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â”‚ FormData (audio.webm)
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SERVER (Express/Node.js)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  STEP 1: SPEECH-TO-TEXT (STT)                           â”‚   â”‚
â”‚  â”‚  Route: POST /api/speech-to-text                        â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚  â”‚                                                     â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  1. Receive audio.webm via multer                 â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  2. Convert to File object                        â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  3. Send to OpenAI Whisper API                    â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     - Model: whisper-1                            â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     - Language: fr (franÃ§ais)                     â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  4. Return transcribed text                       â”‚ â”‚   â”‚
â”‚  â”‚  â”‚                                                     â”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                                       â”‚
â”‚                          â”‚ text: "l'utilisateur a dit..."       â”‚
â”‚                          â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  STEP 2: GESTION DE CONVERSATION (LLM)                  â”‚   â”‚
â”‚  â”‚  Route: POST /api/chat                                  â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚  â”‚                                                     â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  1. Receive { sessionId, userMessage }            â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  2. Load session from storage (MemStorage)        â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  3. Detect clues in user message                  â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  4. Save user message to conversation history     â”‚ â”‚   â”‚
â”‚  â”‚  â”‚                                                     â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  5. Prepare context for LLM:                      â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     â”‚  SYSTEM PROMPT                          â”‚   â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     â”‚  â”œâ”€ Persona: "Peter" AI Ã©ducatif       â”‚   â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     â”‚  â”œâ”€ Context: indices trouvÃ©s            â”‚   â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     â”‚  â”œâ”€ Rules: rÃ©ponses courtes 1-2 phrasesâ”‚   â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     â”‚  â””â”€ Behavior: encourageant, positif    â”‚   â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     â”‚  CONVERSATION HISTORY                   â”‚   â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     â”‚  â””â”€ Last 6 messages (sliding window)   â”‚   â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚   â”‚
â”‚  â”‚  â”‚                                                     â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  6. Call OpenAI GPT-4o-mini:                      â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     - Model: gpt-4o-mini                          â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     - max_tokens: 150                             â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     - temperature: 0.7                            â”‚ â”‚   â”‚
â”‚  â”‚  â”‚                                                     â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  7. Save assistant response to history            â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  8. Update session (found clues, score)           â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  9. Return response                                â”‚ â”‚   â”‚
â”‚  â”‚  â”‚                                                     â”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                                       â”‚
â”‚                          â”‚ response: "Bravo! ADN trouvÃ©!"       â”‚
â”‚                          â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  STEP 3: TEXT-TO-SPEECH (TTS)                          â”‚   â”‚
â”‚  â”‚  Route: POST /api/text-to-speech                       â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚  â”‚                                                     â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  1. Receive { text }                              â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  2. Call ElevenLabs API                           â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     - Voice ID: ErXwobaYiN019PkySvjV              â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     - Model: eleven_multilingual_v2               â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     - Stability: 0.5                              â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     - Similarity boost: 0.75                      â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  3. Return audio/mpeg stream                      â”‚ â”‚   â”‚
â”‚  â”‚  â”‚                                                     â”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â”‚ audio/mpeg Blob
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CLIENT (React/TypeScript)                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Audio Playback                                          â”‚   â”‚
â”‚  â”‚  - Create Audio element                                  â”‚   â”‚
â”‚  â”‚  - Display Peter avatar with animation                   â”‚   â”‚
â”‚  â”‚  - Play audio response                                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Flux de DonnÃ©es DÃ©taillÃ©

### 1ï¸âƒ£ SPEECH-TO-TEXT (STT)

**Fichier**: `server/routes.ts:88-108`

```typescript
// L'audio arrive en format WebM
POST /api/speech-to-text
â”œâ”€ Input: FormData with audio.webm file
â”œâ”€ Processing:
â”‚  â”œâ”€ Multer receives file in memory buffer
â”‚  â”œâ”€ Convert buffer to File object
â”‚  â””â”€ OpenAI Whisper API call
â”‚     â”œâ”€ model: 'whisper-1'
â”‚     â”œâ”€ language: 'fr'
â”‚     â””â”€ file: audio.webm
â””â”€ Output: { text: "transcription franÃ§aise" }
```

**Technologies utilisÃ©es**:
- **OpenAI Whisper**: ModÃ¨le de reconnaissance vocale state-of-the-art
- **Multer**: Middleware pour gÃ©rer les fichiers multipart
- **WebM**: Format audio lÃ©ger pour le web

---

### 2ï¸âƒ£ GESTION DE CONVERSATION (LLM)

**Fichier**: `server/routes.ts:155-230`

```typescript
POST /api/chat
â”œâ”€ Input: { sessionId, userMessage }
â”œâ”€ Processing:
â”‚  â”œâ”€ Load session state from storage
â”‚  â”œâ”€ Detect clues in user message (detectClue function)
â”‚  â”œâ”€ Save user message to conversation history
â”‚  â”œâ”€ Build context:
â”‚  â”‚  â”œâ”€ System prompt (persona + rules + found clues)
â”‚  â”‚  â””â”€ Last 6 messages (sliding window for context)
â”‚  â”œâ”€ GPT-4o-mini API call
â”‚  â”‚  â”œâ”€ model: 'gpt-4o-mini'
â”‚  â”‚  â”œâ”€ max_tokens: 150
â”‚  â”‚  â””â”€ temperature: 0.7
â”‚  â”œâ”€ Save assistant response
â”‚  â””â”€ Update session (clues, score)
â””â”€ Output: { response, detectedClue, foundClues }
```

**SystÃ¨me de MÃ©moire Actuel**:

```javascript
// Fichier: server/storage.ts
class MemStorage {
  // Stockage en mÃ©moire RAM (non persistant)
  private sessions: Map<string, TutorialSession>
  private messages: Map<string, ConversationMessage>

  // Historique de conversation par session
  getSessionMessages(sessionId) {
    // Retourne tous les messages de la session, triÃ©s par date
  }
}
```

**Contexte envoyÃ© au LLM**:
```javascript
[
  {
    role: 'system',
    content: `Tu es Peter, un assistant IA Ã©ducatif...
              Indices dÃ©jÃ  trouvÃ©s: ${foundClues.join(', ')}
              RÃ¨gles: ...`
  },
  ...last6Messages.map(msg => ({
    role: msg.role,  // 'user' ou 'assistant'
    content: msg.content
  }))
]
```

---

### 3ï¸âƒ£ TEXT-TO-SPEECH (TTS)

**Fichier**: `server/routes.ts:110-153`

```typescript
POST /api/text-to-speech
â”œâ”€ Input: { text: "Bravo! Vous avez trouvÃ© l'ADN!" }
â”œâ”€ Processing:
â”‚  â””â”€ ElevenLabs API call
â”‚     â”œâ”€ Voice ID: ErXwobaYiN019PkySvjV
â”‚     â”œâ”€ Model: eleven_multilingual_v2
â”‚     â”œâ”€ Stability: 0.5 (variabilitÃ© de la voix)
â”‚     â””â”€ Similarity boost: 0.75 (fidÃ©litÃ© Ã  la voix)
â””â”€ Output: audio/mpeg stream
```

---

## ğŸ¯ Fine-Tuning: MÃ©moire (RAG)

### Option 1: RAG Simple (RecommandÃ© pour MVP)

ImplÃ©mentez un systÃ¨me de contexte enrichi sans base vectorielle:

```typescript
// server/routes.ts - Modifier la fonction chat

// 1. CrÃ©er une base de connaissances
const KNOWLEDGE_BASE = {
  "ADN": {
    definition: "L'ADN est la molÃ©cule qui porte l'information gÃ©nÃ©tique...",
    hints: ["double hÃ©lice", "code gÃ©nÃ©tique", "cellules"],
    educational_facts: [
      "L'ADN est prÃ©sent dans chaque cellule de votre corps",
      "Il dÃ©termine vos caractÃ©ristiques hÃ©rÃ©ditaires"
    ]
  },
  "plastique": {
    definition: "Le plastique est un polymÃ¨re synthÃ©tique...",
    hints: ["pollution", "ocÃ©ans", "recyclage"],
    educational_facts: [
      "8 millions de tonnes de plastique finissent dans les ocÃ©ans chaque annÃ©e",
      "Le plastique met 450 ans Ã  se dÃ©composer"
    ]
  },
  // ... autres indices
};

// 2. Modifier le system prompt pour inclure le contexte
const systemPrompt = `Tu es Peter, un assistant IA Ã©ducatif...

Indices dÃ©jÃ  trouvÃ©s: ${session.foundClues.join(', ')}

CONTEXTE Ã‰DUCATIF:
${session.foundClues.map(clue =>
  `- ${clue}: ${KNOWLEDGE_BASE[clue].definition}`
).join('\n')}

CONNAISSANCES DISPONIBLES:
${Object.entries(KNOWLEDGE_BASE)
  .filter(([key]) => !session.foundClues.includes(key))
  .map(([key, value]) => `- ${key}: ${value.hints.join(', ')}`)
  .join('\n')}

RÃ¨gles:
- RÃ©ponds en 1-2 phrases courtes et encourageantes
- Utilise les connaissances ci-dessus pour enrichir tes rÃ©ponses
- Si l'utilisateur pose une question, utilise les faits Ã©ducatifs pertinents
- Guide avec des questions ouvertes
`;
```

### Option 2: RAG AvancÃ© avec Vector Database

Pour une solution plus scalable:

```bash
npm install @pinecone-database/pinecone openai
```

**ImplÃ©mentation**:

```typescript
// server/rag.ts (nouveau fichier)
import { Pinecone } from '@pinecone-database/pinecone';
import OpenAI from 'openai';

const pinecone = new Pinecone({ apiKey: process.env.PINECONE_API_KEY });
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

export class RAGSystem {
  private index;

  constructor() {
    this.index = pinecone.Index('dilemme-plastique');
  }

  // 1. CrÃ©er des embeddings pour la base de connaissances
  async indexKnowledge(documents: Array<{id: string, text: string, metadata: any}>) {
    for (const doc of documents) {
      const embedding = await openai.embeddings.create({
        model: 'text-embedding-3-small',
        input: doc.text,
      });

      await this.index.upsert([{
        id: doc.id,
        values: embedding.data[0].embedding,
        metadata: doc.metadata,
      }]);
    }
  }

  // 2. Rechercher le contexte pertinent
  async searchRelevantContext(query: string, topK: number = 3) {
    const queryEmbedding = await openai.embeddings.create({
      model: 'text-embedding-3-small',
      input: query,
    });

    const results = await this.index.query({
      vector: queryEmbedding.data[0].embedding,
      topK,
      includeMetadata: true,
    });

    return results.matches.map(match => match.metadata.text);
  }

  // 3. Enrichir le contexte de la conversation
  async enrichContext(userMessage: string, foundClues: string[]) {
    const relevantContext = await this.searchRelevantContext(userMessage);

    return {
      relevantFacts: relevantContext,
      clueHints: foundClues.map(clue =>
        `Vous avez dÃ©jÃ  dÃ©couvert: ${clue}`
      )
    };
  }
}

// Utilisation dans routes.ts
const ragSystem = new RAGSystem();

app.post('/api/chat', async (req, res) => {
  // ... code existant ...

  // Enrichir avec RAG
  const enrichedContext = await ragSystem.enrichContext(userMessage, session.foundClues);

  const systemPrompt = `Tu es Peter, un assistant IA Ã©ducatif...

  CONTEXTE PERTINENT:
  ${enrichedContext.relevantFacts.join('\n')}

  INDICES TROUVÃ‰S:
  ${enrichedContext.clueHints.join('\n')}

  RÃ¨gles: ...`;

  // ... suite du code ...
});
```

### Option 3: Fine-Tuning du ModÃ¨le OpenAI

Pour un comportement trÃ¨s spÃ©cifique Ã  votre cas d'usage:

```typescript
// PrÃ©parer des donnÃ©es d'entraÃ®nement (JSONL format)
const trainingData = [
  {
    messages: [
      { role: "system", content: "Tu es Peter, assistant Ã©ducatif..." },
      { role: "user", content: "Je vois quelque chose qui ressemble Ã  une hÃ©lice" },
      { role: "assistant", content: "IntÃ©ressant! Une double hÃ©lice peut-Ãªtre? Qu'est-ce que cela pourrait reprÃ©senter dans le contexte scientifique?" }
    ]
  },
  // ... minimum 10 exemples, idÃ©alement 50-100
];

// Script pour fine-tuner (Ã  exÃ©cuter hors de l'app)
async function fineTuneModel() {
  const openai = new OpenAI();

  // 1. Upload training file
  const file = await openai.files.create({
    file: fs.createReadStream("training_data.jsonl"),
    purpose: "fine-tune",
  });

  // 2. Create fine-tuning job
  const fineTune = await openai.fineTuning.jobs.create({
    training_file: file.id,
    model: "gpt-4o-mini-2024-07-18",
  });

  console.log("Fine-tuning job created:", fineTune.id);
}

// Puis dans routes.ts, utiliser le modÃ¨le fine-tunÃ©:
const completion = await openai.chat.completions.create({
  model: 'ft:gpt-4o-mini-2024-07-18:your-org:custom-model:id',
  messages: chatMessages,
  // ...
});
```

---

## ğŸ¤ Customisation de la Voix (TTS)

### Option 1: Voix Custom avec ElevenLabs (DÃ©jÃ  utilisÃ©)

**1. CrÃ©er une voix custom via ElevenLabs Dashboard**:

```bash
# 1. Aller sur https://elevenlabs.io/voice-lab
# 2. Cliquer sur "Instant Voice Cloning" ou "Professional Voice Cloning"
```

**Voice Cloning Options**:

**A. Instant Voice Cloning** (Rapide, 1 minute d'audio):
```
- Upload 1-5 fichiers audio de la voix cible
- DurÃ©e totale: 1-5 minutes
- QualitÃ©: Bonne pour la plupart des cas
- CoÃ»t: ~$1-5 par voix
```

**B. Professional Voice Cloning** (Haute qualitÃ©, 30 minutes d'audio):
```
- Upload 30+ minutes d'audio de haute qualitÃ©
- Meilleure fidÃ©litÃ© et naturalitÃ©
- CoÃ»t: ~$330 par voix
```

**2. Utiliser la voix dans le code**:

```typescript
// server/routes.ts:119
app.post('/api/text-to-speech', async (req, res) => {
  const { text } = req.body;

  // Modifier le VOICE_ID avec votre voix custom
  const VOICE_ID = 'YOUR_CUSTOM_VOICE_ID'; // Obtenu aprÃ¨s crÃ©ation

  const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${VOICE_ID}`, {
    method: 'POST',
    headers: {
      'Accept': 'audio/mpeg',
      'Content-Type': 'application/json',
      'xi-api-key': process.env.ELEVENLABS_API_KEY
    },
    body: JSON.stringify({
      text,
      model_id: 'eleven_multilingual_v2', // Support franÃ§ais
      voice_settings: {
        stability: 0.5,           // 0-1: Consistance de la voix
        similarity_boost: 0.75,   // 0-1: FidÃ©litÃ© Ã  la voix originale
        style: 0.5,               // 0-1: ExagÃ©ration du style (v2 model)
        use_speaker_boost: true   // AmÃ©liore la clartÃ©
      }
    })
  });

  const audioBuffer = await response.arrayBuffer();
  res.set('Content-Type', 'audio/mpeg');
  res.send(Buffer.from(audioBuffer));
});
```

**3. ParamÃ¨tres de fine-tuning de la voix**:

```typescript
const VOICE_PRESETS = {
  energetic: {
    stability: 0.3,          // Plus de variation
    similarity_boost: 0.8,
    style: 0.7,              // Plus d'Ã©motion
  },
  calm: {
    stability: 0.7,          // Plus stable
    similarity_boost: 0.6,
    style: 0.3,              // Moins d'Ã©motion
  },
  educational: {
    stability: 0.5,          // Ã‰quilibrÃ©
    similarity_boost: 0.75,
    style: 0.5,
    speaking_rate: 1.0,      // Vitesse normale
  },
  child_friendly: {
    stability: 0.4,
    similarity_boost: 0.7,
    style: 0.6,              // Plus expressif
  }
};

// Utiliser selon le contexte
const voiceSettings = VOICE_PRESETS.educational;
```

### Option 2: OpenAI TTS (Alternative)

```typescript
app.post('/api/text-to-speech', async (req, res) => {
  const { text } = req.body;

  const mp3 = await openai.audio.speech.create({
    model: "tts-1-hd",  // ou "tts-1" (plus rapide, moins cher)
    voice: "nova",      // alloy, echo, fable, onyx, nova, shimmer
    input: text,
    speed: 1.0,         // 0.25 Ã  4.0
  });

  const buffer = Buffer.from(await mp3.arrayBuffer());
  res.set('Content-Type', 'audio/mpeg');
  res.send(buffer);
});
```

**Voix disponibles OpenAI**:
- `alloy` - Neutre, polyvalente
- `echo` - Masculine, claire
- `fable` - Masculine britannique
- `onyx` - Masculine profonde
- `nova` - FÃ©minine Ã©nergique â­ (recommandÃ© pour Peter)
- `shimmer` - FÃ©minine douce

### Option 3: Coqui TTS (Open Source, Self-Hosted)

```bash
npm install @coqui/tts
```

```typescript
import { TTS } from '@coqui/tts';

const tts = new TTS();

app.post('/api/text-to-speech', async (req, res) => {
  const { text } = req.body;

  // Charger un modÃ¨le prÃ©-entraÃ®nÃ©
  const audioBuffer = await tts.synthesize({
    text,
    model: 'tts_models/fr/css10/vits', // ModÃ¨le franÃ§ais
    speakerId: 0,
  });

  res.set('Content-Type', 'audio/wav');
  res.send(audioBuffer);
});
```

---

## ğŸ”§ Variables d'Environnement Requises

```bash
# .env
OPENAI_API_KEY=sk-...                    # Pour STT (Whisper) et LLM (GPT)
ELEVENLABS_API_KEY=...                   # Pour TTS
PINECONE_API_KEY=...                     # (Optionnel) Pour RAG avancÃ©
```

---

## ğŸ“Š Comparaison des Solutions

### MÃ©moire (RAG)

| Solution | ComplexitÃ© | CoÃ»t | Performance | Use Case |
|----------|-----------|------|-------------|----------|
| **RAG Simple** | â­ | Gratuit | Bon pour <100 docs | MVP, petite base |
| **Pinecone RAG** | â­â­â­ | ~$70/mois | Excellent | Production, scaling |
| **Fine-tuning** | â­â­â­â­ | ~$8 + $0.012/1K tokens | TrÃ¨s spÃ©cifique | Comportement unique |

### Voix (TTS)

| Solution | QualitÃ© | Latence | CoÃ»t/1K chars | Customisation |
|----------|---------|---------|---------------|---------------|
| **ElevenLabs** | â­â­â­â­â­ | ~1-2s | $0.30 | Voice cloning â­ |
| **OpenAI TTS** | â­â­â­â­ | ~0.5-1s | $0.015 | 6 voix fixes |
| **Coqui TTS** | â­â­â­ | <0.5s | Gratuit | Open source |

---

## ğŸš€ Recommandations d'ImplÃ©mentation

### Pour la MÃ©moire (Peter):
1. **Court terme (1 semaine)**: ImplÃ©menter RAG Simple avec KNOWLEDGE_BASE
2. **Moyen terme (1 mois)**: Migrer vers Pinecone + embeddings si >100 documents
3. **Long terme**: Fine-tuner GPT-4o-mini avec vos propres exemples de conversations

### Pour la Voix:
1. **ImmÃ©diat**: Tester les 6 voix OpenAI pour trouver celle qui convient
2. **Court terme**: CrÃ©er une voix custom ElevenLabs avec Instant Voice Cloning
3. **Moyen terme**: Professional Voice Cloning si budget le permet

---

## ğŸ“ Fichiers Ã  Modifier

| FonctionnalitÃ© | Fichier | Ligne |
|----------------|---------|-------|
| STT Config | `server/routes.ts` | 88-108 |
| LLM Prompt | `server/routes.ts` | 179-188 |
| LLM Model | `server/routes.ts` | 198-203 |
| TTS Config | `server/routes.ts` | 110-153 |
| TTS Validation | `server/routes.ts` | 161-165 |
| Voice ID | `server/routes.ts` | 119 |
| Voice Settings | `server/routes.ts` | 135-138 |
| Storage | `server/storage.ts` | 17-82 |
| Messages Window | `server/routes.ts` | 192 |
| Audio Playback | `client/src/hooks/useVoiceInteraction.ts` | 184-280 |
| Audio Cleanup | `client/src/hooks/useVoiceInteraction.ts` | 199-210 |
| Blob Validation | `client/src/lib/api.ts` | 74-78 |
| Audio Timeouts | `client/src/components/TutorialScreen.tsx` | 310, 323-330 |
| Replay Button | `client/src/pages/Home.tsx` | 52-63 |

---

## ğŸ’¡ Conseils de Fine-Tuning

### Pour amÃ©liorer Peter (LLM):

```typescript
// 1. Augmenter la fenÃªtre de contexte
...messages.slice(-10)  // Au lieu de -6

// 2. Ajouter de la personnalitÃ©
const systemPrompt = `Tu es Peter, un assistant IA Ã©ducatif avec ces traits:
- Enthousiaste et encourageant
- Utilise des mÃ©taphores scientifiques
- Pose des questions socratiques
- S'adapte au niveau de l'utilisateur
- Utilise parfois des emojis (ğŸ§¬ pour ADN, ğŸŒ pour plastique)

Ton style de rÃ©ponse:
- Format: [RÃ©action Ã©motionnelle] + [Question/Information] + [Encouragement]
- Exemple: "Wow, excellente observation! ğŸ‰ Une double hÃ©lice... cela te fait penser Ã  quoi en biologie? Continue d'explorer!"
`;

// 3. Ajuster la tempÃ©rature selon le contexte
const temperature = session.foundClues.length === 0 ? 0.9 : 0.6;
// Plus crÃ©atif au dÃ©but, plus prÃ©cis quand on avance
```

### Pour amÃ©liorer la voix:

```typescript
// Adapter les paramÃ¨tres selon le contexte
const getVoiceSettings = (message: string) => {
  if (message.includes('Bravo') || message.includes('Excellent')) {
    return { stability: 0.3, similarity_boost: 0.8, style: 0.8 }; // Enthousiaste
  }
  if (message.includes('?')) {
    return { stability: 0.5, similarity_boost: 0.75, style: 0.6 }; // Questionnement
  }
  return { stability: 0.5, similarity_boost: 0.75, style: 0.5 }; // Normal
};
```

---

## ğŸ” Debugging & Monitoring

```typescript
// Ajouter des logs dÃ©taillÃ©s
app.post('/api/chat', async (req, res) => {
  const startTime = Date.now();

  console.log('[CHAT] User message:', userMessage);
  console.log('[CHAT] Found clues:', session.foundClues);

  const completion = await openai.chat.completions.create({...});

  console.log('[CHAT] LLM response:', assistantResponse);
  console.log('[CHAT] Processing time:', Date.now() - startTime, 'ms');
  console.log('[CHAT] Tokens used:', completion.usage);

  // ...
});
```

---

## ğŸ“š Ressources Utiles

### Documentation du Projet
- [README.md](./README.md) - Documentation principale
- [CHANGELOG.md](./CHANGELOG.md) - Historique complet des modifications

### APIs & Services
- [OpenAI Whisper Docs](https://platform.openai.com/docs/guides/speech-to-text)
- [OpenAI GPT Fine-tuning](https://platform.openai.com/docs/guides/fine-tuning)
- [OpenAI TTS Docs](https://platform.openai.com/docs/guides/text-to-speech)
- [ElevenLabs Voice Lab](https://elevenlabs.io/voice-lab)
- [Pinecone RAG Guide](https://docs.pinecone.io/guides/data/understanding-hybrid-search)
