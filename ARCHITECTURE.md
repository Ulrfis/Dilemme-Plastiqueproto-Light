# Architecture du SystÃ¨me de Conversation Vocale

## ğŸš€ AmÃ©liorations v1.2.0 - Optimisations Latence Majeure

### Overview des Optimisations
La version 1.2.0 apporte des **amÃ©liorations architecturales majeures** qui rÃ©duisent la latence conversationnelle de **6-11 secondes**!

**Phase 1 - Quick Wins (2-4s):**
- TTS Response Caching (MD5 + LRU)
- API Connection Warming (OpenAI keepalive 30s)
- DNS Prefetch/Preconnect (api.openai.com, api.elevenlabs.io)
- Smart Audio Keepalive (2s â†’ 5s, -60% overhead)

**Phase 2 - Streaming Architecture (4-7s):**
- LLM Sentence Streaming (SSE progressive)
- ElevenLabs Streaming TTS (audio chunks)
- Audio Queue Manager (lecture sÃ©quentielle)
- Progressive UI (ChatGPT-style display)

ğŸ“– **Documentation complÃ¨te:**
- [PHASE1_OPTIMIZATIONS.md](./PHASE1_OPTIMIZATIONS.md) - Guide dÃ©taillÃ© Phase 1
- [PHASE2_OPTIMIZATIONS.md](./PHASE2_OPTIMIZATIONS.md) - Guide dÃ©taillÃ© Phase 2

### Architecture Streaming (Phase 2)

**Flux Avant (SÃ©quentiel):**
```
User â†’ STT (2-7s) â†’ [WAIT] â†’ LLM (3-8s) â†’ [WAIT] â†’ TTS (1-3s) â†’ Play
Total: 7-20 secondes
```

**Flux AprÃ¨s (ParallÃ¨le):**
```
User â†’ STT (2-7s) â†’ LLM Sentence 1 (1s) â”¬â†’ TTS 1 (0.3s) â†’ Play (IMMEDIATE!)
                                        â”œâ†’ TTS 2 (0.3s) â†’ Queue
                                        â””â†’ TTS 3 (0.3s) â†’ Queue

User entend la rÃ©ponse Ã  ~3.3s (vs 7s avant)
```

**Key Features:**
- **Server-Sent Events (SSE):** Streaming LLM responses sentence-by-sentence
- **Parallel Processing:** TTS starts while LLM still generating
- **Audio Queue:** Sequential playback of sentence chunks
- **Cache Integration:** Phase 1 cache still active for repeated phrases

### Endpoints Phase 2

**Nouveaux endpoints streaming:**
```
POST /api/chat/stream          # SSE streaming LLM (sentence-by-sentence)
POST /api/text-to-speech/stream # ElevenLabs streaming TTS
```

**Endpoints legacy (fallback):**
```
POST /api/chat                 # Non-streaming LLM (toujours disponible)
POST /api/text-to-speech       # Non-streaming TTS (avec cache Phase 1)
```

---

## ğŸ†• AmÃ©liorations v1.1.0 - Robustesse Mobile

### ProblÃ¨mes RÃ©solus
La version 1.1.0 apporte des corrections critiques pour garantir la fiabilitÃ© du flux audio sur mobile.

#### 1. Flux Audio BloquÃ© AprÃ¨s PremiÃ¨re Interaction
**SymptÃ´me** : Peter ne parlait plus aprÃ¨s la premiÃ¨re conversation, particuliÃ¨rement sur Safari iOS.

**Causes IdentifiÃ©es** :
- Blobs audio vides ou invalides non dÃ©tectÃ©s
- Ã‰lÃ©ments `<audio>` non nettoyÃ©s entre les lectures
- Ã‰tats bloquÃ©s sans mÃ©canisme de rÃ©cupÃ©ration
- Timeouts trop courts pour connexions mobiles lentes
- Audio play() appelÃ© sans attendre le chargement

**Solutions ImplÃ©mentÃ©es** :

```typescript
// 1. Validation des blobs audio (client/src/lib/api.ts:74-78)
const blob = await response.blob();
if (!blob || blob.size === 0) {
  throw new Error('Received empty or invalid audio blob from server');
}

// 2. Validation cÃ´tÃ© serveur (server/routes.ts:161-165)
const audioBuffer = await response.arrayBuffer();
if (audioBuffer.byteLength === 0) {
  throw new Error('Received empty audio from ElevenLabs');
}

// 3. Nettoyage de l'Audio element (client/src/hooks/useVoiceInteraction.ts:199-210)
if (audioElementRef.current) {
  audioElementRef.current.pause();
  audioElementRef.current.src = '';
  audioElementRef.current.load();  // Force cleanup
  audioElementRef.current = null;
}

// 4. PrÃ©-chargement et attente readyState (client/src/hooks/useVoiceInteraction.ts:215-221)
const audio = new Audio();
audio.preload = 'auto';
audio.volume = 1.0;
audio.src = audioUrl;
audio.load();

// 5. Attente de l'Ã©vÃ©nement canplay (client/src/hooks/useVoiceInteraction.ts:356-375)
if (audio.readyState >= 2) {
  attemptPlay();
} else {
  audio.addEventListener('canplay', () => {
    attemptPlay();
  }, { once: true });
}

// 6. DÃ©tection de blocage (client/src/components/TutorialScreen.tsx:323-330)
const startTimeoutId = setTimeout(() => {
  if (audioState === 'playing' && !isAudioPlaying) {
    console.warn('Audio stuck - recovering');
    stopAudio();
    recoverFromError();
  }
}, 5000);

// 7. Timeouts amÃ©liorÃ©s (client/src/components/TutorialScreen.tsx:310)
const safetyTimeout = estimatedDuration + 10000; // +10s au lieu de +5s
```

#### 2. Bouton "Rejouer le Tutoriel"
**ProblÃ¨me** : Le bouton retournait Ã  l'Ã©cran tutoriel au lieu de l'Ã©cran de titre.

**Solution** :
```typescript
// client/src/pages/Home.tsx:52-63
const handleReplay = async () => {
  // RÃ©initialisation complÃ¨te
  setUserName('');
  setSessionId('');
  setScore(0);
  setFoundClues([]);

  // Retour Ã  l'Ã©cran de titre (au lieu de 'tutorial')
  setCurrentScreen('title');
};
```

### Impact
- **FiabilitÃ©** : Flux audio fonctionne de maniÃ¨re cohÃ©rente sur mobile
- **Robustesse** : RÃ©cupÃ©ration automatique en cas de blocage
- **UX** : ExpÃ©rience utilisateur cohÃ©rente sur tous les appareils

---

## ğŸ“ SchÃ©ma d'Architecture Globale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CLIENT (React/TypeScript)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ VoiceInteractionâ”‚â”€â”€â”€â”€â–¶â”‚ useVoiceInteraction Hook         â”‚   â”‚
â”‚  â”‚   Component     â”‚     â”‚  - MediaRecorder API             â”‚   â”‚
â”‚  â”‚                 â”‚     â”‚  - Audio State Management        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                          â”‚                             â”‚
â”‚         â”‚                          â”‚                             â”‚
â”‚         â–¼                          â–¼                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚           Audio Recording (WebM format)                   â”‚   â”‚
â”‚  â”‚   â€¢ echoCancellation: true                               â”‚   â”‚
â”‚  â”‚   â€¢ noiseSuppression: true                               â”‚   â”‚
â”‚  â”‚   â€¢ sampleRate: 44100                                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â”‚ FormData (audio.webm)
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SERVER (Express/Node.js)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  STEP 1: SPEECH-TO-TEXT (STT)                           â”‚   â”‚
â”‚  â”‚  Route: POST /api/speech-to-text                        â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚  â”‚                                                     â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  1. Receive audio.webm via multer                 â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  2. Convert to File object                        â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  3. Send to OpenAI Whisper API                    â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     - Model: whisper-1                            â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     - Language: fr (franÃ§ais)                     â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  4. Return transcribed text                       â”‚ â”‚   â”‚
â”‚  â”‚  â”‚                                                     â”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                                       â”‚
â”‚                          â”‚ text: "l'utilisateur a dit..."       â”‚
â”‚                          â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  STEP 2: GESTION DE CONVERSATION (LLM)                  â”‚   â”‚
â”‚  â”‚  Route: POST /api/chat                                  â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚  â”‚                                                     â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  1. Receive { sessionId, userMessage }            â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  2. Load session from storage (MemStorage)        â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  3. Detect clues in user message                  â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  4. Save user message to conversation history     â”‚ â”‚   â”‚
â”‚  â”‚  â”‚                                                     â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  5. Prepare context for LLM:                      â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     â”‚  SYSTEM PROMPT                          â”‚   â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     â”‚  â”œâ”€ Persona: "Peter" AI Ã©ducatif       â”‚   â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     â”‚  â”œâ”€ Context: indices trouvÃ©s            â”‚   â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     â”‚  â”œâ”€ Rules: rÃ©ponses courtes 1-2 phrasesâ”‚   â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     â”‚  â””â”€ Behavior: encourageant, positif    â”‚   â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     â”‚  CONVERSATION HISTORY                   â”‚   â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     â”‚  â””â”€ Last 6 messages (sliding window)   â”‚   â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚   â”‚
â”‚  â”‚  â”‚                                                     â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  6. Call OpenAI Assistant API:                    â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     - Assistant ID: asst_P9b5PxMd1k9HjBgbyXI1Cvm9 â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     - Model: gpt-4o-mini                          â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     - Maintains thread for context               â”‚ â”‚   â”‚
â”‚  â”‚  â”‚                                                     â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  7. Save assistant response to history            â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  8. Update session (found clues, score)           â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  9. Return response                                â”‚ â”‚   â”‚
â”‚  â”‚  â”‚                                                     â”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                                       â”‚
â”‚                          â”‚ response: "Bravo! ADN trouvÃ©!"       â”‚
â”‚                          â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  STEP 3: TEXT-TO-SPEECH (TTS)                          â”‚   â”‚
â”‚  â”‚  Route: POST /api/text-to-speech                       â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚  â”‚                                                     â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  1. Receive { text }                              â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  2. Validate text not empty                       â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  3. Call ElevenLabs API                           â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     - Voice ID: CBP9p4KAWPqrMHTDtWPR              â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     - Model: eleven_multilingual_v2               â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     - Stability: 0.5                              â”‚ â”‚   â”‚
â”‚  â”‚  â”‚     - Similarity boost: 0.75                      â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  4. Validate audio not empty                      â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  5. Return audio/mpeg stream                      â”‚ â”‚   â”‚
â”‚  â”‚  â”‚                                                     â”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â”‚ audio/mpeg Blob
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CLIENT (React/TypeScript)                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Audio Playback                                          â”‚   â”‚
â”‚  â”‚  1. Validate blob                                        â”‚   â”‚
â”‚  â”‚  2. Cleanup previous audio element                       â”‚   â”‚
â”‚  â”‚  3. Create new Audio element                             â”‚   â”‚
â”‚  â”‚  4. Configure (preload, volume)                          â”‚   â”‚
â”‚  â”‚  5. Set src and load()                                   â”‚   â”‚
â”‚  â”‚  6. Wait for readyState or canplay event                 â”‚   â”‚
â”‚  â”‚  7. Call play()                                           â”‚   â”‚
â”‚  â”‚  8. Display Peter avatar with animation                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Flux de DonnÃ©es DÃ©taillÃ©

### 1ï¸âƒ£ SPEECH-TO-TEXT (STT)

**Fichier**: `server/routes.ts:88-108`

```typescript
POST /api/speech-to-text
â”œâ”€ Input: FormData with audio.webm file
â”œâ”€ Processing:
â”‚  â”œâ”€ Multer receives file in memory buffer
â”‚  â”œâ”€ Convert buffer to File object
â”‚  â””â”€ OpenAI Whisper API call
â”‚     â”œâ”€ model: 'whisper-1'
â”‚     â”œâ”€ language: 'fr'
â”‚     â””â”€ file: audio.webm
â””â”€ Output: { text: "transcription franÃ§aise" }
```

**Technologies utilisÃ©es**:
- OpenAI Whisper : Reconnaissance vocale
- Multer : Gestion fichiers multipart
- WebM : Format audio pour le web

---

### 2ï¸âƒ£ GESTION DE CONVERSATION (LLM)

**Fichier**: `server/routes.ts:172-342`

```typescript
POST /api/chat
â”œâ”€ Input: { sessionId, userMessage }
â”œâ”€ Processing:
â”‚  â”œâ”€ Load session state from MemStorage
â”‚  â”œâ”€ Detect clues in user message
â”‚  â”œâ”€ Save user message to conversation history
â”‚  â”œâ”€ OpenAI Assistant API call
â”‚  â”‚  â”œâ”€ First message: Create thread
â”‚  â”‚  â”œâ”€ Subsequent: Reuse thread
â”‚  â”‚  â”œâ”€ Assistant ID: asst_P9b5PxMd1k9HjBgbyXI1Cvm9
â”‚  â”‚  â””â”€ Model: gpt-4o-mini
â”‚  â”œâ”€ Save assistant response
â”‚  â””â”€ Update session (clues, score)
â””â”€ Output: { response, detectedClue, foundClues }
```

**SystÃ¨me de MÃ©moire**:
- MemStorage : Stockage en mÃ©moire RAM (non persistant)
- Thread OpenAI : Maintient contexte conversationnel
- Sliding window : Derniers messages disponibles

**DÃ©tection des Indices**:
```typescript
const TARGET_CLUES = [
  { keyword: "ADN", variants: ["adn", "acide dÃ©soxyribonuclÃ©ique", "gÃ©nÃ©tique", "double hÃ©lice"] },
  { keyword: "bÃ©bÃ©", variants: ["bÃ©bÃ©", "bebe", "nourrisson", "enfant", "nouveau-nÃ©"] },
  { keyword: "penseur de Rodin", variants: ["penseur", "rodin", "sculpture", "statue penseur"] },
  { keyword: "plastique", variants: ["plastique", "pollution plastique", "dÃ©chets plastiques", "pollution"] }
];
```

---

### 3ï¸âƒ£ TEXT-TO-SPEECH (TTS)

**Fichier**: `server/routes.ts:116-170`

```typescript
POST /api/text-to-speech
â”œâ”€ Input: { text: "Bravo! Vous avez trouvÃ© l'ADN!" }
â”œâ”€ Processing:
â”‚  â”œâ”€ Validate text not empty
â”‚  â””â”€ ElevenLabs API call
â”‚     â”œâ”€ Voice ID: CBP9p4KAWPqrMHTDtWPR (Peter mai 2025 FR)
â”‚     â”œâ”€ Model: eleven_multilingual_v2
â”‚     â”œâ”€ Stability: 0.5
â”‚     â””â”€ Similarity boost: 0.75
â”œâ”€ Validate: audio not empty
â””â”€ Output: audio/mpeg stream
```

---

## ğŸ¯ Endpoints API

### POST `/api/speech-to-text`
Transcrit un fichier audio en texte.

**Request:**
```http
POST /api/speech-to-text
Content-Type: multipart/form-data

audio: <file.webm>
```

**Response:**
```json
{
  "text": "Je vois une double hÃ©lice dans l'image"
}
```

---

### POST `/api/chat/stream` âš¡ NEW (Phase 2)
Envoie un message Ã  l'assistant IA et reÃ§oit une rÃ©ponse streaming via SSE.

**Request:**
```json
{
  "sessionId": "uuid-v4",
  "userMessage": "Je vois une double hÃ©lice"
}
```

**Response (Server-Sent Events):**
```
Content-Type: text/event-stream

data: {"type":"sentence","text":"Bravo!","index":1}

data: {"type":"sentence","text":"C'est l'ADN!","index":2}

data: {"type":"complete","fullResponse":"Bravo! C'est l'ADN!","foundClues":["ADN"],"detectedClue":"ADN"}
```

**Event Types:**
- `sentence`: Sentence complÃ¨te envoyÃ©e progressivement
- `complete`: Fin du stream avec mÃ©tadonnÃ©es (clues, etc.)
- `error`: Erreur pendant le streaming

---

### POST `/api/chat` (Legacy - Fallback)
Version non-streaming (toujours disponible pour compatibilitÃ©).

**Request:**
```json
{
  "sessionId": "uuid-v4",
  "userMessage": "Je vois une double hÃ©lice"
}
```

**Response:**
```json
{
  "response": "Bravo! Une double hÃ©lice, c'est trÃ¨s bien vu!",
  "detectedClue": "ADN",
  "foundClues": ["ADN"]
}
```

---

### POST `/api/text-to-speech/stream` âš¡ NEW (Phase 2)
GÃ©nÃ¨re un fichier audio Ã  partir de texte avec streaming.

**Request:**
```json
{
  "text": "Bravo! Tu as trouvÃ© l'ADN!"
}
```

**Response:**
```
Content-Type: audio/mpeg
Transfer-Encoding: chunked
X-Cache: MISS (or HIT if cached)

<streaming audio chunks>
```

**Features:**
- Streaming audio chunks pendant gÃ©nÃ©ration
- Cache Phase 1 toujours actif (`X-Cache: HIT` si en cache)
- `optimize_streaming_latency: 3` pour ElevenLabs

---

### POST `/api/text-to-speech` (Legacy - avec cache)
Version non-streaming avec cache Phase 1.

**Request:**
```json
{
  "text": "Bravo! Tu as trouvÃ© l'ADN!"
}
```

**Response:**
```
Content-Type: audio/mpeg
X-Cache: HIT (or MISS)

<binary audio data>
```

### POST `/api/sessions`
CrÃ©e une nouvelle session utilisateur.

**Request:**
```json
{
  "userName": "Sophie",
  "audioMode": "voice"
}
```

**Response:**
```json
{
  "id": "uuid-v4",
  "userName": "Sophie",
  "foundClues": [],
  "score": 0,
  "audioMode": "voice",
  "completed": 0,
  "createdAt": "2025-11-15T10:30:00Z"
}
```

### GET `/api/sessions/:id`
RÃ©cupÃ¨re une session existante.

### PATCH `/api/sessions/:id`
Met Ã  jour une session (score, indices trouvÃ©s, etc.).

---

## ğŸ”§ Variables d'Environnement

```bash
# .env
OPENAI_API_KEY=sk-...          # Pour STT (Whisper) et LLM (Assistant API)
ELEVENLABS_API_KEY=...         # Pour TTS
```

**Configuration OpenAI:**
- Organisation : `org-z0AK8zYLTeapGaiDZFQ5co2N`
- Assistant ID : `asst_P9b5PxMd1k9HjBgbyXI1Cvm9`

**Configuration ElevenLabs:**
- Voice ID : `CBP9p4KAWPqrMHTDtWPR` (Peter mai 2025 FR)
- Model : `eleven_multilingual_v2`

---

## ğŸ“ Fichiers Principaux

| FonctionnalitÃ© | Fichier | Description |
|----------------|---------|-------------|
| STT Config | `server/routes.ts:88-108` | Configuration Whisper |
| LLM Chat | `server/routes.ts:172-342` | OpenAI Assistant API |
| TTS Config | `server/routes.ts:116-170` | Configuration ElevenLabs |
| TTS Validation | `server/routes.ts:161-165` | Validation audio cÃ´tÃ© serveur |
| Storage | `server/storage.ts:17-82` | MemStorage (sessions, messages) |
| Audio Playback | `client/src/hooks/useVoiceInteraction.ts:184-407` | Lecture audio avec prÃ©-chargement |
| Audio Cleanup | `client/src/hooks/useVoiceInteraction.ts:199-210` | Nettoyage Audio element |
| Blob Validation | `client/src/lib/api.ts:74-78` | Validation blob cÃ´tÃ© client |
| Audio Timeouts | `client/src/components/TutorialScreen.tsx:310, 323-330` | Timeouts de sÃ©curitÃ© |
| Replay Button | `client/src/pages/Home.tsx:52-63` | Bouton rejouer le tutoriel |

---

## ğŸ“š Ressources

### Documentation du Projet
- [README.md](./README.md) - Documentation principale
- [CHANGELOG.md](./CHANGELOG.md) - Historique des modifications

### APIs
- [OpenAI Whisper](https://platform.openai.com/docs/guides/speech-to-text)
- [OpenAI Assistant API](https://platform.openai.com/docs/assistants/overview)
- [ElevenLabs TTS](https://elevenlabs.io/docs)
